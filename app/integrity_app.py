"""
RxHCC Integrity Dashboard
==========================
Streamlit ê¸°ë°˜ ë³´í—˜ ì²­êµ¬ ë¬´ê²°ì„± ê²€ì¦ ëŒ€ì‹œë³´ë“œ.
ì‹¤í–‰: streamlit run app/integrity_app.py
"""
import streamlit as st
import pandas as pd
import json
import sys
import os
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from engine.rules import (
    RxHCCRuleEngine,
    ClaimRecord, 
    ValidationResult,
    Severity,
    ICD_NDC_VALID_MAPPINGS,
    GLP1_NDC_PREFIXES,
    GLP1_VALID_ICD_PREFIXES
)
from engine.langgraph_integrity import run_validation
from engine.sagemaker_replication import SyntheticClaimGenerator, PandasBatchValidator

# ============================================================
# í˜ì´ì§€ ì„¤ì •
# ============================================================
st.set_page_config(
    page_title="RxHCC Integrity Dashboard",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .severity-critical {
        background-color: #FF4B4B;
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 0.85em;
    }
    .severity-warning {
        background-color: #FFA62F;
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 0.85em;
    }
    .severity-pass {
        background-color: #21BA45;
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 0.85em;
    }
    .severity-info {
        background-color: #54C8FF;
        color: white;
        padding: 4px 12px;
        border-radius: 12px;
        font-weight: bold;
        font-size: 0.85em;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 12px;
        color: white;
        text-align: center;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    .stTabs [data-baseweb="tab"] {
        padding: 10px 20px;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================================
if "validation_history" not in st.session_state:
    st.session_state.validation_history = []
if "batch_results" not in st.session_state:
    st.session_state.batch_results = None
if "generated_data" not in st.session_state:
    st.session_state.generated_data = None

# ============================================================
# ì‚¬ì´ë“œë°”
# ============================================================
with st.sidebar:
    st.image("https://img.icons8.com/color/96/hospital.png", width=64)
    st.title("RxHCC")
    st.caption("ë³´í—˜ ì²­êµ¬ ë¬´ê²°ì„± ê²€ì¦ ì‹œìŠ¤í…œ")
    st.divider()
    
    # ë„¤ë¹„ê²Œì´ì…˜
    # ë„¤ë¹„ê²Œì´ì…˜ / Navigation
    page = st.radio(
        "ğŸ“ Navigation", 
        [
            "ğŸ” ì‹¤ì‹œê°„ ê²€ì‚¬ (Real-time Scan)", 
            "ğŸ“‹ ë°°ì¹˜ ë°ëª¨ (Batch Demo)", 
            "ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Data Preview)", 
            "ğŸ“– ê·œì¹™ ì‚¬ì „ (Rule Dictionary)", 
            "ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Analytics Dashboard)"
        ],
        index=0
    )
    
    st.divider()
    # ì‹œìŠ¤í…œ ìƒíƒœ
    st.subheader("âš™ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")
    try:
        from langgraph.graph import StateGraph
        st.success("âœ… LangGraph í™œì„±")
    except ImportError:
        st.warning("âš ï¸ LangGraph ë¯¸ì„¤ì¹˜ (ìˆœì°¨ ì‹¤í–‰ ëª¨ë“œ)")
        
    try:
        import sagemaker
        st.success("âœ… SageMaker SDK í™œì„±")
    except ImportError:
        st.info("â„¹ï¸ Pandas ë¡œì»¬ ëª¨ë“œ")
        
    st.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    st.divider()
    st.markdown("**[GitHub Repository](https://github.com/sechan9999/RxHCC)**")

# ============================================================
# í—¬í¼ í•¨ìˆ˜
# ============================================================
def severity_badge(severity: str) -> str:
    """ì‹¬ê°ë„ ë°°ì§€ HTML"""
    css_class = f"severity-{severity.lower()}"
    emoji = {"CRITICAL": "ğŸ”´", "WARNING": "ğŸŸ¡", "PASS": "ğŸŸ¢", "INFO": "ğŸ”µ"}.get(severity, "âšª")
    return f'<span class="{css_class}">{emoji} {severity}</span>'

def render_results(results: list):
    """ê²€ì¦ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ë Œë”ë§"""
    if not results:
        st.info("ê²€ì¦ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    for r in results:
        sev = r.get("severity", "INFO")
        if sev == "CRITICAL":
            icon = "ğŸ”´"
            expander_type = "error"
        elif sev == "WARNING":
            icon = "ğŸŸ¡"
            expander_type = "warning"
        elif sev == "PASS":
            icon = "ğŸŸ¢"
            expander_type = "success"
        else:
            icon = "ğŸ”µ"
            expander_type = "info"
            
        with st.expander(f"{icon} [{sev}] {r.get('rule_name', 'Unknown')}"):
            st.markdown(f"**ê·œì¹™ ID:** `{r.get('rule_id', 'N/A')}`")
            st.markdown(f"**ë©”ì‹œì§€:** {r.get('message', '')}")
            
            details = r.get("details", {})
            if details:
                st.json(details)

def get_predefined_scenarios():
    """ì‚¬ì „ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤"""
    return {
        "âœ… ì •ìƒ: ì œ2í˜• ë‹¹ë‡¨ + Metformin": {
            "claim_id": "DEMO-001",
            "patient_id": "PAT-10001",
            "icd_codes": "E11.9",
            "ndc_codes": "00002-1433-80",
            "hcc_codes": "HCC19",
            "description": "ì œ2í˜• ë‹¹ë‡¨(E11.9) í™˜ìì—ê²Œ Metformin ì²˜ë°©. ì •ìƒ ì¼€ì´ìŠ¤."
        },
        "ğŸ”´ ì¶©ëŒ: ì œ1í˜• + ì œ2í˜• ë‹¹ë‡¨ ë™ì‹œ ì§„ë‹¨": {
            "claim_id": "DEMO-002",
            "patient_id": "PAT-10002",
            "icd_codes": "E10.9,E11.65",
            "ndc_codes": "00088-2500-33",
            "hcc_codes": "HCC18",
            "description": "ì œ1í˜•ê³¼ ì œ2í˜• ë‹¹ë‡¨ê°€ ë™ì‹œì— ì§„ë‹¨ë¨. ìƒí˜¸ ë°°íƒ€ì  ì½”ë“œ ì¶©ëŒ."
        },
        "ğŸ”´ GLP-1 ì˜¤ë‚¨ìš©: ì ì‘ì¦ ì—†ì´ ì²˜ë°©": {
            "claim_id": "DEMO-003",
            "patient_id": "PAT-10003",
            "icd_codes": "I10",
            "ndc_codes": "00169-4060-12",
            "hcc_codes": "",
            "description": "ê³ í˜ˆì••(I10) í™˜ìì—ê²Œ GLP-1(Ozempic) ì²˜ë°©. ì ì‘ì¦(ë‹¹ë‡¨/ë¹„ë§Œ) ì—†ìŒ."
        },
        "ğŸ”´ GLP-1 + ì œ1í˜• ë‹¹ë‡¨": {
            "claim_id": "DEMO-004",
            "patient_id": "PAT-10004",
            "icd_codes": "E10.9",
            "ndc_codes": "00169-4060-12",
            "hcc_codes": "",
            "description": "ì œ1í˜• ë‹¹ë‡¨(E10) í™˜ìì—ê²Œ GLP-1 ì²˜ë°©. GLP-1ì€ ì œ1í˜• ì ì‘ì¦ì´ ì•„ë‹˜."
        },
        "ğŸ”´ HCC Upcoding: í•©ë³‘ì¦ ì—†ëŠ” ë‹¹ë‡¨ì— HCC18": {
            "claim_id": "DEMO-005",
            "patient_id": "PAT-10005",
            "icd_codes": "E11.9",
            "ndc_codes": "00002-1433-80",
            "hcc_codes": "HCC18",
            "description": "í•©ë³‘ì¦ ì—†ëŠ” ë‹¹ë‡¨(E11.9)ì— í•©ë³‘ì¦ HCC(HCC18) ë§¤í•‘. Upcoding ì˜ì‹¬."
        },
        "ğŸŸ¡ NDC ë¶ˆì¼ì¹˜: ê³ í˜ˆì••ì— ì¸ìŠë¦°": {
            "claim_id": "DEMO-006",
            "patient_id": "PAT-10006",
            "icd_codes": "I10",
            "ndc_codes": "00088-2500-33",
            "hcc_codes": "",
            "description": "ê³ í˜ˆì•• ì§„ë‹¨ì— ì¸ìŠë¦° ì²˜ë°©. ì§„ë‹¨-ì•½ë¬¼ ë¶ˆì¼ì¹˜."
        },
        "âœ… ì •ìƒ: ë¹„ë§Œ + Wegovy (GLP-1)": {
            "claim_id": "DEMO-007",
            "patient_id": "PAT-10007",
            "icd_codes": "E66.01",
            "ndc_codes": "00169-4060-13",
            "hcc_codes": "",
            "description": "ë¹„ë§Œ(E66.01) í™˜ìì—ê²Œ Wegovy ì²˜ë°©. GLP-1 ì ì‘ì¦ ìˆìŒ."
        },
    }

# ============================================================
# í˜ì´ì§€ 1: ì‹¤ì‹œê°„ ê²€ì‚¬
# ============================================================
if page == "ğŸ” ì‹¤ì‹œê°„ ê²€ì‚¬ (Real-time Scan)":
    st.title("ğŸ” ì‹¤ì‹œê°„ ë¬´ê²°ì„± ê²€ì‚¬ (Real-time Integrity Scan)")
    st.markdown("í™˜ìì˜ **ì§„ë‹¨ì½”ë“œ(ICD)**ì™€ **ì•½ë¬¼ì½”ë“œ(NDC)**ë¥¼ ì…ë ¥í•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤.\n\nVerify claims by entering Patient **Diagnosis (ICD)** and **Drug (NDC)** codes.")
    
    tab1, tab2 = st.tabs(["ğŸ“ ì§ì ‘ ì…ë ¥ (Manual Input)", "ğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ (Scenario Selection)"])
    
    with tab1:
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("í™˜ì ì •ë³´ (Patient Info)")
            claim_id = st.text_input("Claim ID", value="CLM-TEST-001", key="manual_claim_id")
            patient_id = st.text_input("Patient ID", value="PAT-00001", key="manual_patient_id")
            provider_id = st.text_input("Provider ID", value="PRV-1234", key="manual_provider_id")
            
        with col2:
            st.subheader("ì½”ë“œ ì…ë ¥ (Code Input)")
            icd_input = st.text_input(
                "ICD ì½”ë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", 
                value="E11.9",
                help="ì˜ˆ: E11.9, E10.65, I10",
                key="manual_icd"
            )
            ndc_input = st.text_input(
                "NDC ì½”ë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", 
                value="00002-1433-80",
                help="ì˜ˆ: 00002-1433-80, 00169-4060-12",
                key="manual_ndc"
            )
            hcc_input = st.text_input(
                "HCC ì½”ë“œ (ì‰¼í‘œë¡œ êµ¬ë¶„, ì„ íƒì‚¬í•­)",
                value="",
                help="ì˜ˆ: HCC18, HCC19",
                key="manual_hcc"
            )
            
        if st.button("ğŸš€ ê²€ì¦ ì‹¤í–‰ (Run Validation)", type="primary", use_container_width=True, key="manual_validate"):
            if not icd_input.strip() or not ndc_input.strip():
                st.error("ICD ì½”ë“œì™€ NDC ì½”ë“œë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                claim_data = {
                    "claim_id": claim_id,
                    "patient_id": patient_id,
                    "icd_codes": icd_input,
                    "ndc_codes": ndc_input,
                    "hcc_codes": hcc_input,
                    "provider_id": provider_id,
                    "claim_date": datetime.now().strftime("%Y-%m-%d"),
                    "claim_amount": 0
                }
                
                with st.spinner("ê²€ì¦ ì¤‘..."):
                    result = run_validation(claim_data)
                    
                # ê²°ê³¼ í‘œì‹œ
                st.divider()
                risk_level = result.get("metadata", {}).get("risk_level", "UNKNOWN")
                risk_score = result.get("metadata", {}).get("risk_score", 0)
                
                # ë©”íŠ¸ë¦­ ì¹´ë“œ
                m1, m2, m3, m4 = st.columns(4)
                with m1: st.metric("ë¦¬ìŠ¤í¬ ë“±ê¸‰", risk_level)
                with m2: st.metric("ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´", risk_score)
                with m3:
                    critical_count = sum(1 for r in result["results"] if r.get("severity") == "CRITICAL")
                    st.metric("ğŸ”´ Critical", critical_count)
                with m4:
                    warning_count = sum(1 for r in result["results"] if r.get("severity") == "WARNING")
                    st.metric("ğŸŸ¡ Warning", warning_count)
                    
                st.divider()
                render_results(result["results"])
                
                # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                st.session_state.validation_history.append({
                    "timestamp": datetime.now().strftime("%H:%M:%S"),
                    "claim_id": claim_id,
                    "icd": icd_input,
                    "ndc": ndc_input,
                    "risk_level": risk_level,
                    "risk_score": risk_score,
                    "n_critical": critical_count,
                    "n_warning": warning_count,
                })

    with tab2:
        st.subheader("ì‚¬ì „ ì •ì˜ëœ ì‹œë‚˜ë¦¬ì˜¤ (Predefined Scenarios)")
        scenarios = get_predefined_scenarios()
        selected = st.selectbox("ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ (Select Scenario)", list(scenarios.keys()))
        scenario = scenarios[selected]
        
        st.info(f"**ì„¤ëª…:** {scenario['description']}")
        
        # ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„° í‘œì‹œ
        col_a, col_b = st.columns(2)
        with col_a:
            st.code(f"ICD: {scenario['icd_codes']}\nNDC: {scenario['ndc_codes']}\nHCC: {scenario['hcc_codes']}")
            
        if st.button("ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ (Validate Scenario)", type="primary", use_container_width=True, key="scenario_validate"):
            with st.spinner("ê²€ì¦ ì¤‘..."):
                result = run_validation(scenario)
                
            risk_level = result.get("metadata", {}).get("risk_level", "UNKNOWN")
            risk_score = result.get("metadata", {}).get("risk_score", 0)
            
            m1, m2 = st.columns(2)
            with m1: st.metric("ë¦¬ìŠ¤í¬ ë“±ê¸‰", risk_level)
            with m2: st.metric("ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´", risk_score)
            
            render_results(result["results"])

    # ê²€ì¦ íˆìŠ¤í† ë¦¬
    if st.session_state.validation_history:
        st.divider()
        st.subheader("ğŸ“œ ê²€ì¦ íˆìŠ¤í† ë¦¬")
        history_df = pd.DataFrame(st.session_state.validation_history)
        st.dataframe(history_df, use_container_width=True, hide_index=True)
        
        if st.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” (Clear History)"):
            st.session_state.validation_history = []
            st.rerun()

# ============================================================
# í˜ì´ì§€ 2: ë°°ì¹˜ ë°ëª¨
# ============================================================
elif page == "ğŸ“‹ ë°°ì¹˜ ë°ëª¨ (Batch Demo)":
    st.title("ğŸ“‹ ë°°ì¹˜ ê²€ì¦ ë°ëª¨ (Batch Validation Demo)")
    st.markdown("ì‚¬ì „ ì •ì˜ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë°°ì¹˜ë¡œ ê²€ì¦í•˜ê±°ë‚˜, í•©ì„± ë°ì´í„°ë¥¼ ìƒì„±í•˜ì—¬ ëŒ€ëŸ‰ ê²€ì¦í•©ë‹ˆë‹¤.\n\nValidate scenarios in batch or generate synthetic data for large-scale testing.")
    
    tab1, tab2 = st.tabs(["ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ ë°°ì¹˜ (Scenario Batch)", "ğŸ”¬ í•©ì„± ë°ì´í„° ìƒì„±/ê²€ì¦ (Synthetic Data)"])
    
    with tab1:
        st.subheader("7ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì¼ê´„ ê²€ì¦ (Batch Validate 7 Scenarios)")
        if st.button("â–¶ï¸ ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì‹¤í–‰ (Run All)", type="primary", use_container_width=True, key="batch_scenarios"):
            scenarios = get_predefined_scenarios()
            progress = st.progress(0)
            all_results = []
            
            for i, (name, scenario) in enumerate(scenarios.items()):
                result = run_validation(scenario)
                risk_level = result.get("metadata", {}).get("risk_level", "UNKNOWN")
                risk_score = result.get("metadata", {}).get("risk_score", 0)
                critical_count = sum(1 for r in result["results"] if r.get("severity") == "CRITICAL")
                warning_count = sum(1 for r in result["results"] if r.get("severity") == "WARNING")
                
                all_results.append({
                    "ì‹œë‚˜ë¦¬ì˜¤": name,
                    "Claim ID": scenario["claim_id"],
                    "ICD": scenario["icd_codes"],
                    "NDC": scenario["ndc_codes"],
                    "ë¦¬ìŠ¤í¬ ë“±ê¸‰": risk_level,
                    "ìŠ¤ì½”ì–´": risk_score,
                    "ğŸ”´ Critical": critical_count,
                    "ğŸŸ¡ Warning": warning_count,
                })
                progress.progress((i + 1) / len(scenarios))
                
            st.session_state.batch_results = pd.DataFrame(all_results)
            
        if st.session_state.batch_results is not None:
            df = st.session_state.batch_results
            
            # ìš”ì•½ ë©”íŠ¸ë¦­
            c1, c2, c3, c4 = st.columns(4)
            with c1: st.metric("ì „ì²´ ì‹œë‚˜ë¦¬ì˜¤", len(df))
            with c2: 
                high_risk = len(df[df["ë¦¬ìŠ¤í¬ ë“±ê¸‰"].isin(["HIGH", "MEDIUM"])])
                st.metric("ìœ„í—˜ ê°ì§€", high_risk)
            with c3:
                total_critical = df["ğŸ”´ Critical"].sum()
                st.metric("ì´ Critical", int(total_critical))
            with c4:
                total_warning = df["ğŸŸ¡ Warning"].sum()
                st.metric("ì´ Warning", int(total_warning))
                
            st.divider()
            
            # ê²°ê³¼ í…Œì´ë¸” (ì¡°ê±´ë¶€ ìƒ‰ìƒ)
            def color_risk(val):
                colors = {
                    "HIGH": "background-color: #FF4B4B; color: white;",
                    "MEDIUM": "background-color: #FFA62F; color: white;",
                    "LOW": "background-color: #FECF33;",
                    "MINIMAL": "background-color: #21BA45; color: white;",
                }
                return colors.get(val, "")

            styled_df = df.style.applymap(color_risk, subset=["ë¦¬ìŠ¤í¬ ë“±ê¸‰"])
            st.dataframe(styled_df, use_container_width=True, hide_index=True)

    with tab2:
        st.subheader("í•©ì„± ë°ì´í„° ìƒì„± & ëŒ€ëŸ‰ ê²€ì¦ (Generate Synthetic Data)")
        col1, col2, col3 = st.columns(3)
        with col1: n_records = st.slider("ë ˆì½”ë“œ ìˆ˜ (Count)", 100, 5000, 1000, step=100)
        with col2: anomaly_rate = st.slider("ì´ìƒ ë¹„ìœ¨ (Anomaly Rate %)", 5, 50, 15)
        with col3: seed = st.number_input("ëœë¤ ì‹œë“œ (Random Seed)", value=42, min_value=0)
        
        if st.button("ğŸ”¬ ë°ì´í„° ìƒì„± & ê²€ì¦ (Generate & Validate)", type="primary", use_container_width=True, key="generate_validate"):
            with st.spinner(f"{n_records}ê°œ ë ˆì½”ë“œ ìƒì„± ì¤‘..."):
                generator = SyntheticClaimGenerator(seed=seed)
                df = generator.generate(n_records=n_records, anomaly_rate=anomaly_rate / 100)
            
            st.success(f"âœ… {len(df)}ê°œ ë ˆì½”ë“œ ìƒì„± ì™„ë£Œ!")
            
            with st.spinner("ë°°ì¹˜ ê²€ì¦ ì¤‘..."):
                validator = PandasBatchValidator()
                validated_df = validator.validate_dataframe(df)
                summary = validator.get_summary(validated_df)
                
            st.session_state.generated_data = validated_df
            
            # ìš”ì•½ ëŒ€ì‹œë³´ë“œ
            st.divider()
            st.subheader("ğŸ“Š ê²€ì¦ ê²°ê³¼ ìš”ì•½")
            m1, m2, m3, m4 = st.columns(4)
            with m1: st.metric("ì´ ì²­êµ¬", summary["total_claims"])
            with m2: st.metric("ğŸš© í”Œë˜ê·¸", summary["flagged_claims"])
            with m3: st.metric("í†µê³¼ìœ¨", f"{summary['pass_rate']}%")
            with m4: st.metric("ìœ„í—˜ ê¸ˆì•¡", f"${summary['total_amount_at_risk']:,.0f}")
            
            # ì‹¬ê°ë„ ë¶„í¬ ì°¨íŠ¸
            st.divider()
            col_a, col_b = st.columns(2)
            with col_a:
                st.subheader("ì‹¬ê°ë„ ë¶„í¬")
                sev_df = pd.DataFrame(
                    list(summary["severity_distribution"].items()),
                    columns=["Severity", "Count"]
                )
                st.bar_chart(sev_df.set_index("Severity"))
            with col_b:
                if summary["anomaly_distribution"]:
                    st.subheader("ì´ìƒ ìœ í˜• ë¶„í¬")
                    anom_df = pd.DataFrame(
                        list(summary["anomaly_distribution"].items()),
                        columns=["Type", "Count"]
                    )
                    st.bar_chart(anom_df.set_index("Type"))

# ============================================================
# í˜ì´ì§€ 3: ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
# ============================================================
elif page == "ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Data Preview)":
    st.title("ğŸ“Š ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Data Preview)")
    
    tab1, tab2 = st.tabs(["ğŸ“ ìƒì„±ëœ ë°ì´í„° (Generated)", "ğŸ“¤ CSV ì—…ë¡œë“œ (Upload CSV)"])
    
    with tab1:
        if st.session_state.generated_data is not None:
            df = st.session_state.generated_data
            st.metric("ì´ ë ˆì½”ë“œ", len(df))
            
            # í•„í„°ë§
            col1, col2 = st.columns(2)
            with col1:
                severity_filter = st.multiselect(
                    "ì‹¬ê°ë„ í•„í„° (Severity Filter)", ["PASS", "WARNING", "CRITICAL"], default=["PASS", "WARNING", "CRITICAL"]
                )
            with col2:
                if "anomaly_type" in df.columns:
                    anomaly_filter = st.multiselect(
                        "ì´ìƒ ìœ í˜• í•„í„° (Anomaly Type Filter)", df["anomaly_type"].unique().tolist(), default=df["anomaly_type"].unique().tolist()
                    )
                else:
                    anomaly_filter = None
                    
            filtered = df[df["max_severity"].isin(severity_filter)]
            if anomaly_filter is not None and "anomaly_type" in filtered.columns:
                filtered = filtered[filtered["anomaly_type"].isin(anomaly_filter)]
                
            st.dataframe(
                filtered.drop(columns=["validation_results"], errors="ignore"),
                use_container_width=True,
                hide_index=True
            )
            
            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            csv = filtered.to_csv(index=False).encode("utf-8")
            st.download_button(
                "ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                csv,
                f"rxhcc_validated_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                "text/csv"
            )
            
            # íŠ¹ì • ë ˆì½”ë“œ ìƒì„¸ ë³´ê¸°
            st.divider()
            st.subheader("ğŸ” ë ˆì½”ë“œ ìƒì„¸ ê²€ì¦ ê²°ê³¼")
            selected_claim = st.selectbox(
                "Claim ID ì„ íƒ", filtered["claim_id"].tolist()[:50] # ìƒìœ„ 50ê°œë§Œ
            )
            
            if selected_claim:
                row = filtered[filtered["claim_id"] == selected_claim].iloc[0]
                c1, c2, c3 = st.columns(3)
                with c1: st.code(f"ICD: {row['icd_codes']}")
                with c2: st.code(f"NDC: {row['ndc_codes']}")
                with c3: st.code(f"Severity: {row['max_severity']}")
                
                if "validation_results" in row:
                    try:
                        results = json.loads(row["validation_results"])
                        render_results(results)
                    except json.JSONDecodeError:
                        st.warning("ê²€ì¦ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ’¡ 'ë°°ì¹˜ ë°ëª¨' íƒ­ì—ì„œ ë¨¼ì € ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")

    with tab2:
        st.subheader("CSV íŒŒì¼ ì—…ë¡œë“œí•˜ì—¬ ê²€ì¦")
        st.markdown("""
        **í•„ìˆ˜ ì»¬ëŸ¼:**
        - `claim_id`: ì²­êµ¬ ID
        - `icd_codes`: ICD ì½”ë“œ (ì‰¼í‘œ êµ¬ë¶„)
        - `ndc_codes`: NDC ì½”ë“œ (ì‰¼í‘œ êµ¬ë¶„)
        
        **ì„ íƒ ì»¬ëŸ¼:**
        `patient_id`, `hcc_codes`, `provider_id`, `claim_amount`
        """)
        
        uploaded = st.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])
        if uploaded:
            df = pd.read_csv(uploaded)
            st.success(f"âœ… {len(df)}ê°œ ë ˆì½”ë“œ ë¡œë“œë¨")
            st.dataframe(df.head(10), use_container_width=True)
            
            if st.button("ğŸš€ ì—…ë¡œë“œ ë°ì´í„° ê²€ì¦", type="primary", key="upload_validate"):
                with st.spinner("ê²€ì¦ ì¤‘..."):
                    validator = PandasBatchValidator()
                    validated = validator.validate_dataframe(df)
                    summary = validator.get_summary(validated)
                    
                st.session_state.generated_data = validated
                
                m1, m2, m3 = st.columns(3)
                with m1: st.metric("ì´ ì²­êµ¬", summary["total_claims"])
                with m2: st.metric("ğŸš© í”Œë˜ê·¸", summary["flagged_claims"])
                with m3: st.metric("í†µê³¼ìœ¨", f"{summary['pass_rate']}%")
                
                st.dataframe(
                    validated.drop(columns=["validation_results"], errors="ignore"),
                    use_container_width=True
                )

# ============================================================
# í˜ì´ì§€ 4: ê·œì¹™ ì‚¬ì „
# ============================================================
elif page == "ğŸ“– ê·œì¹™ ì‚¬ì „ (Rule Dictionary)":
    st.title("ğŸ“– ê²€ì¦ ê·œì¹™ ì‚¬ì „ (Rule Dictionary)")
    st.markdown("í˜„ì¬ ì‹œìŠ¤í…œì— ë“±ë¡ëœ ëª¨ë“  ê²€ì¦ ê·œì¹™ê³¼ ë§¤í•‘ í…Œì´ë¸”ì„ ì¡°íšŒí•©ë‹ˆë‹¤.\n\nBrowse all validation rules and mapping tables registered in the system.")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ICD-NDC ë§¤í•‘ (Mapping)", "âš¡ ì¶©ëŒ ê·œì¹™ (Conflicts)", "ğŸ’Š GLP-1 ê·œì¹™ (GLP-1 Rules)"])
    
    with tab1:
        st.subheader("ICD-NDC í—ˆìš© ë§¤í•‘ í…Œì´ë¸”")
        for icd_prefix, mapping in ICD_NDC_VALID_MAPPINGS.items():
            with st.expander(f"**{icd_prefix}** â€” {mapping['description']}"):
                for ndc in mapping["valid_ndc_prefixes"]:
                    st.code(ndc, language=None)
                    
    with tab2:
        st.subheader("ICD ì½”ë“œ ì¶©ëŒ ê·œì¹™")
        from engine.rules import ICD_CONFLICT_RULES
        for rule in ICD_CONFLICT_RULES:
            severity_color = "ğŸ”´" if rule["severity"] == Severity.CRITICAL else "ğŸŸ¡"
            with st.expander(f"{severity_color} {rule['rule_id']}: {rule['name']}"):
                st.markdown(f"**ê·¸ë£¹ A:** `{rule['codes_a']}`")
                st.markdown(f"**ê·¸ë£¹ B:** `{rule['codes_b']}`")
                st.markdown(f"**ì‹¬ê°ë„:** {rule['severity'].value}")
                st.markdown(f"**ë©”ì‹œì§€:** {rule['message']}")
                
    with tab3:
        st.subheader("GLP-1 íŠ¹ë³„ ê²€ì¦ ê·œì¹™")
        st.markdown("### GLP-1 NDC ì½”ë“œ")
        for ndc in GLP1_NDC_PREFIXES:
            st.code(ndc, language=None)
            
        st.markdown("### í—ˆìš© ì ì‘ì¦ (ICD prefix)")
        for icd in GLP1_VALID_ICD_PREFIXES:
            desc = ICD_NDC_VALID_MAPPINGS.get(icd, {}).get("description", "")
            st.markdown(f"- **{icd}**: {desc}")
            
        st.warning("""
        **GLP-1 ê²€ì¦ ê·œì¹™:**
        1. GLP-1 ì²˜ë°© ì‹œ E11(ì œ2í˜• ë‹¹ë‡¨) ë˜ëŠ” E66(ë¹„ë§Œ) ì§„ë‹¨ì´ ë°˜ë“œì‹œ í•„ìš”
        2. E10(ì œ1í˜• ë‹¹ë‡¨)ì— GLP-1 ì²˜ë°©ì€ CRITICAL ìœ„ë°˜
        """)

# ============================================================
# í˜ì´ì§€ 5: ë¶„ì„ ëŒ€ì‹œë³´ë“œ
# ============================================================
elif page == "ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Analytics Dashboard)":
    st.title("ğŸ“ˆ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Analytics Dashboard)")
    
    if st.session_state.generated_data is not None:
        df = st.session_state.generated_data
        
        # KPI ì¹´ë“œ
        total = len(df)
        flagged = df["is_flagged"].sum()
        pass_rate = (total - flagged) / total * 100 if total > 0 else 0
        
        c1, c2, c3, c4, c5 = st.columns(5)
        with c1: st.metric("ì´ ì²­êµ¬", f"{total:,}")
        with c2: st.metric("ğŸš© í”Œë˜ê·¸", f"{int(flagged):,}")
        with c3: st.metric("í†µê³¼ìœ¨", f"{pass_rate:.1f}%")
        with c4: 
            if "claim_amount" in df.columns:
                total_amt = df["claim_amount"].sum()
                st.metric("ì´ ì²­êµ¬ì•¡", f"${total_amt:,.0f}")
        with c5:
            if "claim_amount" in df.columns:
                risk_amt = df[df["is_flagged"]]["claim_amount"].sum()
                st.metric("ìœ„í—˜ ê¸ˆì•¡", f"${risk_amt:,.0f}")
                
        st.divider()
        
        # ì°¨íŠ¸ë“¤
        col_a, col_b = st.columns(2)
        with col_a:
            st.subheader("ì‹¬ê°ë„ ë¶„í¬")
            sev_counts = df["max_severity"].value_counts()
            st.bar_chart(sev_counts)
        with col_b:
            if "anomaly_type" in df.columns:
                st.subheader("ì´ìƒ ìœ í˜• ë¶„í¬")
                anom_counts = df["anomaly_type"].value_counts()
                st.bar_chart(anom_counts)
                
        # Provider ë¶„ì„
        if "provider_id" in df.columns:
            st.divider()
            st.subheader("ğŸ¥ Providerë³„ ìœ„ë°˜ í˜„í™©")
            provider_stats = df.groupby("provider_id").agg(
                total_claims=("claim_id", "count"),
                flagged_claims=("is_flagged", "sum"),
                total_amount=("claim_amount", "sum") if "claim_amount" in df.columns else ("claim_id", "count"),
            ).reset_index()
            
            provider_stats["flag_rate"] = (
                provider_stats["flagged_claims"] / provider_stats["total_claims"] * 100
            ).round(1)
            
            # ìœ„ë°˜ìœ¨ ë†’ì€ ìˆœ
            top_providers = provider_stats.nlargest(10, "flag_rate")
            st.dataframe(top_providers, use_container_width=True, hide_index=True)
            
        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        if "claim_date" in df.columns:
            st.divider()
            st.subheader("ğŸ“… ì›”ë³„ ì²­êµ¬ ì¶”ì´")
            try:
                df_time = df.copy()
                df_time["claim_date"] = pd.to_datetime(df_time["claim_date"])
                df_time["month"] = df_time["claim_date"].dt.to_period("M").astype(str)
                
                monthly = df_time.groupby("month").agg(
                    total=("claim_id", "count"),
                    flagged=("is_flagged", "sum")
                ).reset_index()
                
                st.line_chart(monthly.set_index("month"))
            except Exception:
                st.info("ë‚ ì§œ ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ’¡ 'ë°°ì¹˜ ë°ëª¨' íƒ­ì—ì„œ ë¨¼ì € ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. (Please generate data in 'Batch Demo' tab first.)")
        
        if st.button("ğŸ”¬ ìƒ˜í”Œ ë°ì´í„° ë¹ ë¥´ê²Œ ìƒì„± (Generate 500 Samples)", type="primary"):
            with st.spinner("ìƒì„± ì¤‘..."):
                gen = SyntheticClaimGenerator(seed=42)
                df = gen.generate(500, 0.15)
                validator = PandasBatchValidator()
                validated = validator.validate_dataframe(df)
            
            st.session_state.generated_data = validated
            st.success("âœ… ì™„ë£Œ! í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•©ë‹ˆë‹¤.")
            st.rerun()

# ============================================================
# í‘¸í„°
# ============================================================
st.divider()
st.markdown(
    """
    <div style="text-align: center; color: #888; font-size: 0.85em;">
        RxHCC Integrity Dashboard v2.0 | 
        <a href="https://github.com/sechan9999/RxHCC" target="_blank">GitHub</a> | 
        Built with Streamlit, LangGraph, Pandas
    </div>
    """,
    unsafe_allow_html=True
)
